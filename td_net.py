# -*- coding: utf-8 -*-
"""TD-Net.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HFsqkZxlZ9jSPrtXw-BzhwS_7ms_gFlI

# Data Loading and Preprocessing

## Downlaoding and Loading Datasets
"""

!pip install opendatasets --upgrade --quiet

# !rm -r "/content/tuberculosis-tb-chest-xray-dataset"

dataset_url = "https://www.kaggle.com/datasets/tawsifurrahman/tuberculosis-tb-chest-xray-dataset"

import opendatasets as od
od.download(dataset_url,force=True)

"""### Reading the metadata"""

import pandas as pd

normal_df = pd.read_excel("/content/tuberculosis-tb-chest-xray-dataset/TB_Chest_Radiography_Database/Normal.metadata.xlsx")

normal_df

tuberculosis_df = pd.read_excel("/content/tuberculosis-tb-chest-xray-dataset/TB_Chest_Radiography_Database/Tuberculosis.metadata.xlsx")

tuberculosis_df

"""The metadata includes information such as image format, size, and URLs. However, these details are not pertinent to the segmentation task and can therefore be excluded from further analysis.

Furthermore the dataset lacks annotations necessary for segmentation, making it more suitable for classification tasks.

### Loading the Data and Performing Data Preprocessing
"""

import tensorflow as tf
from tensorflow.keras.preprocessing import image_dataset_from_directory
from tensorflow.keras.layers import RandomFlip, RandomRotation, RandomZoom
import numpy as np
from tensorflow.keras.preprocessing.image import ImageDataGenerator

"""To decrease computational cost due to lack of resources we will resize the image to 224x224"""

# Define image size and batch size
IMAGE_SIZE = (224, 224)
BATCH_SIZE = 4

dataset_dir = '/content/tuberculosis-tb-chest-xray-dataset/TB_Chest_Radiography_Database'

datagen=ImageDataGenerator(
                           rescale=1./255.,\
                        )

train_dataset = datagen.flow_from_directory(
    dataset_dir,
    target_size=IMAGE_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='binary',
    subset='training',
    color_mode='rgb',
)

import matplotlib.pyplot as plt

# Get the class labels from the dataset
labels = train_dataset.classes
class_names = list(train_dataset.class_indices.keys())

print(class_names)

# Count the number of samples in each class
class_counts = np.bincount(labels)

# Plot the distribution
plt.bar(class_names, class_counts)
plt.title('Class Distribution in Training Data')
plt.xlabel('Class')
plt.ylabel('Number of samples')
plt.show()

def plot_batch_images(batch_data, batch_labels, batch_index):
    plt.figure(figsize=(12, 6))
    for i in range(len(batch_data)):
        ax = plt.subplot(1, len(batch_data), i + 1)
        plt.imshow(batch_data[i])
        # plt.title(f"Label: {int(batch_labels[i])}")
        plt.axis("off")
    # plt.suptitle(f"Batch {batch_index + 1}")
    plt.show()

# Visualize two batches
for batch_index in range(2):
    # Get a batch of images and labels
    batch_data, batch_labels = next(iter(train_dataset))
    # Plot the images in the batch
    plot_batch_images(batch_data, batch_labels, batch_index)

"""## Train Test Split"""

import random
import shutil
import os

data_path = "/content/tuberculosis-tb-chest-xray-dataset/TB_Chest_Radiography_Database"
train_folder = os.path.join(data_path, 'train')
val_folder = os.path.join(data_path, 'eval')
test_folder = os.path.join(data_path, 'test')

# Create destination folders for train, eval, and test sets
for folder_path in [train_folder, val_folder, test_folder]:
    os.makedirs(os.path.join(folder_path, 'Normal'), exist_ok=True)
    os.makedirs(os.path.join(folder_path, 'Tuberculosis'), exist_ok=True)

# Get all images in Normal and Tuberculosis folders
normal_images = os.listdir(os.path.join(data_path, 'Normal'))
tb_images = os.listdir(os.path.join(data_path, 'Tuberculosis'))

# Combine all images from Normal and Tuberculosis folders and shuffle them
all_images = [(f, 'Normal') for f in normal_images] + [(f, 'Tuberculosis') for f in tb_images]
random.seed(42)
random.shuffle(all_images)

# Define train, eval, and test split sizes
train_size = int(len(all_images) * 0.6)
val_size = int(len(all_images) * 0.1)

# Copy images to the respective train, eval, and test folders
for i, (filename, label_dir) in enumerate(all_images):
    if i < train_size:
        dest_folder = train_folder
    elif i < train_size + val_size:
        dest_folder = val_folder
    else:
        dest_folder = test_folder

    # Copy image from the source directory to the destination directory
    source_path = os.path.join(data_path, label_dir, filename)
    dest_path = os.path.join(dest_folder, label_dir, filename)
    shutil.copy(source_path, dest_path)

print("Dataset split into train, eval, and test sets successfully.")

# Define Image Data Generators
train_datagen = ImageDataGenerator(
    rotation_range=20,
    width_shift_range=0.1,
    height_shift_range=0.1,
    shear_range=0.1,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest',
    rescale=1./255)
test_datagen = ImageDataGenerator(rescale=1./255)

# Load data using generators
train_dataset = train_datagen.flow_from_directory(
    train_folder,
    target_size=IMAGE_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='binary',
    shuffle=True
)

val_dataset = train_datagen.flow_from_directory(
    val_folder,
    target_size=IMAGE_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='binary',
    shuffle=True
)

test_dataset = test_datagen.flow_from_directory(
    test_folder,
    target_size=IMAGE_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='binary',
    shuffle=False
)

"""## Image Augmentation"""

import numpy as np
from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img
import os

# Set parameters
augment_count = 5  # Number of augmentations per image
IMAGE_SIZE = (224, 224)  # Define the target image size
data_path = "/content/tuberculosis-tb-chest-xray-dataset/TB_Chest_Radiography_Database"

# Define the ImageDataGenerator for augmentation
datagen = ImageDataGenerator(
    rotation_range=20,
    width_shift_range=0.1,
    height_shift_range=0.1,
    shear_range=0.1,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)

# Function to save augmented images
def augment_and_save_images(image_dir, label):
    # Get all image file paths in the folder
    image_files = os.listdir(image_dir)
    for image_file in image_files:
        img_path = os.path.join(image_dir, image_file)

        # Load the image
        img = load_img(img_path, target_size=IMAGE_SIZE)
        x = img_to_array(img)  # Convert image to array
        x = np.expand_dims(x, axis=0)  # Add batch dimension

        # Generate and save augmented images
        i = 0
        for batch in datagen.flow(x, batch_size=1, save_to_dir=image_dir, save_prefix=f"aug_{label}", save_format='png'):
            i += 1
            if i >= augment_count:
                break  # Stop after generating specified number of augmentations

# Augment images in both "train" and "eval" folders for "Normal" and "Tuberculosis"
for folder_type in ['train', 'eval']:
    folder_path = os.path.join(data_path, folder_type)
    augment_and_save_images(os.path.join(folder_path, 'Normal'), 'Normal')
    augment_and_save_images(os.path.join(folder_path, 'Tuberculosis'), 'Tuberculosis')

print("Augmentation completed and images saved in both train and eval sets.")

# Define Image Data Generators
train_datagen = ImageDataGenerator(
    rotation_range=20,
    width_shift_range=0.1,
    height_shift_range=0.1,
    shear_range=0.1,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest',
    rescale=1./255)
test_datagen = ImageDataGenerator(rescale=1./255)

# Load data using generators
train_dataset = train_datagen.flow_from_directory(
    train_folder,
    target_size=IMAGE_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='binary',
    shuffle=True
)

val_dataset = train_datagen.flow_from_directory(
    val_folder,
    target_size=IMAGE_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='binary',
    shuffle=True
)

test_dataset = test_datagen.flow_from_directory(
    test_folder,
    target_size=IMAGE_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='binary',
    shuffle=False
)

labels = train_dataset.classes

# Count the number of samples in each class
class_counts = np.bincount(labels)

# Plot the distribution
plt.bar(class_names, class_counts)
plt.title('Class Distribution in Training Data')
plt.xlabel('Class')
plt.ylabel('Number of samples')
plt.show()

"""# Model Training"""

class_weights = {0: 0.6, 1: 3.0}

import tensorflow as tf
from tensorflow.keras.layers import Input, Dense, Dropout, GlobalAveragePooling2D, Multiply, Conv2D
from tensorflow.keras.models import Model
from tensorflow.keras.applications import MobileNetV2, DenseNet121, EfficientNetB0

# Channel Attention Layer
class ChannelAttention(tf.keras.layers.Layer):
    def __init__(self, reduction_ratio=8):
        super(ChannelAttention, self).__init__()
        self.reduction_ratio = reduction_ratio

    def build(self, input_shape):
        # Dynamically determine the number of channels from input_shape
        channels = input_shape[-1]
        reduced_channels = max(1, channels // self.reduction_ratio)

        self.dense_avg_1 = Dense(units=reduced_channels, activation='relu')
        self.dense_avg_2 = Dense(units=channels, activation='sigmoid')
        self.dense_max_1 = Dense(units=reduced_channels, activation='relu')
        self.dense_max_2 = Dense(units=channels, activation='sigmoid')

    def call(self, inputs):
        channel_avg = tf.reduce_mean(inputs, axis=[1, 2], keepdims=True)
        channel_max = tf.reduce_max(inputs, axis=[1, 2], keepdims=True)

        avg_dense = self.dense_avg_1(channel_avg)
        avg_dense = self.dense_avg_2(avg_dense)

        max_dense = self.dense_max_1(channel_max)
        max_dense = self.dense_max_2(max_dense)

        channel_attention = Multiply()([inputs, avg_dense + max_dense])
        return channel_attention

# Spatial Attention Layer
class SpatialAttention(tf.keras.layers.Layer):
    def __init__(self):
        super(SpatialAttention, self).__init__()
        self.conv = Conv2D(filters=1, kernel_size=7, padding='same', activation='sigmoid')

    def call(self, inputs):
        avg_pool = tf.reduce_mean(inputs, axis=-1, keepdims=True)
        max_pool = tf.reduce_max(inputs, axis=-1, keepdims=True)
        concat = tf.concat([avg_pool, max_pool], axis=-1)

        spatial_attention = self.conv(concat)
        return Multiply()([inputs, spatial_attention])

# Custom F1 Score Metric
class F1Score(tf.keras.metrics.Metric):
    def __init__(self, name='f1_score', **kwargs):
        super(F1Score, self).__init__(name=name, **kwargs)
        self.precision = tf.keras.metrics.Precision()
        self.recall = tf.keras.metrics.Recall()

    def update_state(self, y_true, y_pred, sample_weight=None):
        self.precision.update_state(y_true, y_pred, sample_weight)
        self.recall.update_state(y_true, y_pred, sample_weight)

    def result(self):
        precision = self.precision.result()
        recall = self.recall.result()
        return 2 * ((precision * recall) / (precision + recall + tf.keras.backend.epsilon()))

    def reset_states(self):
        self.precision.reset_states()
        self.recall.reset_states()

# Helper function to create a base model with L1 regularization
def create_base_model_with_l1(model_fn, input_shape, l1_strength=0.01):
    inputs = Input(shape=input_shape)
    base_model = model_fn(include_top=False, weights='imagenet', input_tensor=inputs)

    # Apply L1 regularization to each trainable layer in the base model
    for layer in base_model.layers:
        if hasattr(layer, 'kernel_regularizer'):
            layer.kernel_regularizer = tf.keras.regularizers.l1(l1_strength)

    return base_model, inputs

# Generalized Model Creation with Attention and L1 Regularization
def create_attention_model(model_fn, input_shape=(224, 224, 3), l1_strength=0.01, name="AttentionModel"):
    # Create base model with L1 regularization using provided function
    base_model, inputs = create_base_model_with_l1(model_fn, input_shape, l1_strength)

    # Apply attention layers
    x = base_model.output
    x = ChannelAttention()(x)
    x = SpatialAttention()(x)

    # Global Pooling and Dense Layers
    x = GlobalAveragePooling2D()(x)
    x = Dense(128, activation='relu')(x)
    x = Dropout(0.4)(x)

    # Output layer for binary classification
    outputs = Dense(1, activation='sigmoid')(x)

    # Create and compile the model
    model = Model(inputs=inputs, outputs=outputs, name=name)
    model.compile(
        optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.0001)
        ,
        loss='binary_crossentropy',
        metrics=[
            'accuracy',
            tf.keras.metrics.Precision(name='precision'),
            tf.keras.metrics.Recall(name='recall'),
            F1Score()  # Using the custom F1Score metric
        ]
    )
    return model

mobile_net_model = create_attention_model(MobileNetV2, input_shape=(224, 224, 3), name="MobileNet_with_Attention")

mobile_net_model.summary()

from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping

early_stopping = EarlyStopping(monitor='val_accuracy', patience=7, restore_best_weights=True)
model_checkpoint = ModelCheckpoint('mobilenet_checkpoint.keras', save_best_only=True, monitor='accuracy')

history = mobile_net_model.fit(train_dataset, validation_data=val_dataset, epochs=20, class_weight=class_weights,callbacks=[early_stopping, model_checkpoint])

"""# Plot Metrics"""

import matplotlib.pyplot as plt

def plot_training_history(history):
    # Extract metrics from history object
    accuracy = history.history['accuracy']
    loss = history.history['loss']
    recall = history.history['recall']

    epochs = range(1, len(accuracy) + 1)

    # Plot accuracy
    plt.figure(figsize=(12, 4))
    plt.subplot(1, 3, 1)
    plt.plot(epochs, accuracy, label='Training Accuracy')
    plt.title('Accuracy')
    plt.xlabel('Epochs')
    plt.ylabel('Accuracy')
    plt.legend()

    # Plot loss
    plt.subplot(1, 3, 2)
    plt.plot(epochs, loss, label='Training Loss')
    plt.title('Loss')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.legend()

    # Plot recall
    plt.subplot(1, 3, 3)
    plt.plot(epochs, recall, label='Training Recall')
    plt.title('Recall')
    plt.xlabel('Epochs')
    plt.ylabel('Recall')
    plt.legend()

    # Adjust layout and show plot
    plt.tight_layout()
    plt.show()

plot_training_history(history)

from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score
import numpy as np

# Step 1: Use model.predict to get predicted probabilities
pred_probabilities = mobile_net_model.predict(test_dataset)
pred_labels = (pred_probabilities > 0.5).astype("int32")  # Convert probabilities to binary labels (0 or 1)

# Step 2: Get true labels from test dataset
true_labels = test_dataset.classes  # Assumes test_dataset is a DirectoryIterator with .classes attribute

# Step 3: Calculate metrics
accuracy = accuracy_score(true_labels, pred_labels)
f1 = f1_score(true_labels, pred_labels)
precision = precision_score(true_labels, pred_labels)
recall = recall_score(true_labels, pred_labels)

# Print the results
print(f"Accuracy: {accuracy:.4f}")
print(f"F1 Score: {f1:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")

"""# GradCam"""

import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras.models import Model
import cv2

def get_gradcam_heatmap(model, img_array, last_conv_layer_name, pred_index=None):
    """
    Generates Grad-CAM heatmap for a given model and input image.
    """
    grad_model = Model(
        inputs=model.inputs,
        outputs=[model.get_layer(last_conv_layer_name).output, model.output]
    )

    with tf.GradientTape() as tape:
        conv_outputs, predictions = grad_model(img_array)
        if pred_index is None:
            pred_index = tf.argmax(predictions[0])
        class_channel = predictions[:, pred_index]

    grads = tape.gradient(class_channel, conv_outputs)
    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))

    conv_outputs = conv_outputs[0]
    heatmap = tf.reduce_sum(conv_outputs * pooled_grads, axis=-1)

    heatmap = np.maximum(heatmap, 0) / np.max(heatmap)
    return heatmap

def overlay_heatmap(heatmap, image, alpha=0.4, colormap='viridis'):
    """
    Overlays the Grad-CAM heatmap on the original image using matplotlib.
    """
    heatmap = np.uint8(255 * heatmap)
    colormap = plt.get_cmap(colormap)
    colormap = colormap(np.arange(256))[:, :3]
    colormap = (colormap * 255).astype(np.uint8)
    heatmap_colored = colormap[heatmap]

    # Resize heatmap to match image size
    heatmap_colored = tf.image.resize(heatmap_colored, (image.shape[0], image.shape[1])).numpy()

    # Normalize image and heatmap
    image = image / 255.0
    heatmap_colored = heatmap_colored / 255.0

    # Overlay the heatmap on the image
    overlay = image * (1 - alpha) + heatmap_colored * alpha
    return overlay

# Visualize Grad-CAM
def visualize_gradcam(image_path, model, last_conv_layer_name, preprocess_input):
    """
    Displays the Grad-CAM heatmap and overlay for an input image.
    """
    # Load and preprocess the image
    img = tf.keras.preprocessing.image.load_img(image_path, target_size=(224, 224))
    img_array = tf.keras.preprocessing.image.img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0)
    img_array = preprocess_input(img_array)

    # Generate Grad-CAM heatmap
    heatmap = get_gradcam_heatmap(model, img_array, last_conv_layer_name)

    # Display the image and Grad-CAM overlay
    img = np.uint8(255 * tf.keras.preprocessing.image.img_to_array(img) / 255.0)
    heatmap_overlay = overlay_heatmap(heatmap, img)

    plt.figure(figsize=(10, 10))
    plt.subplot(1, 2, 1)
    plt.title("Original Image")
    plt.imshow(img)
    plt.axis("off")

    plt.subplot(1, 2, 2)
    plt.title("Grad-CAM Overlay")
    plt.imshow(heatmap_overlay)
    plt.axis("off")
    plt.show()

from tensorflow.keras.applications.mobilenet_v2 import preprocess_input

# Path to the image you want to analyze
image_path = "/content/tuberculosis-tb-chest-xray-dataset/TB_Chest_Radiography_Database/Tuberculosis/Tuberculosis-1.png"

# Name of the last convolutional layer in your model
last_conv_layer_name = "Conv_1"

# Visualize Grad-CAM
visualize_gradcam(image_path, mobile_net_model, last_conv_layer_name, preprocess_input)

from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score
import numpy as np

# Step 1: Use model.predict to get predicted probabilities
pred_probabilities = mobile_net_model.predict(test_dataset)
pred_labels = (pred_probabilities > 0.5).astype("int32")  # Convert probabilities to binary labels (0 or 1)

# Step 2: Get true labels from test dataset
true_labels = test_dataset.classes  # Assumes test_dataset is a DirectoryIterator with .classes attribute

# Step 3: Calculate metrics
accuracy = accuracy_score(true_labels, pred_labels)
f1 = f1_score(true_labels, pred_labels)
precision = precision_score(true_labels, pred_labels)
recall = recall_score(true_labels, pred_labels)

# Print the results
print(f"Accuracy: {accuracy:.4f}")
print(f"F1 Score: {f1:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")